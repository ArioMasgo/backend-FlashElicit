# Flash Elicit API

API para extracci√≥n, clasificaci√≥n de comentarios y generaci√≥n de requisitos No Funcionales basados en ISO 25010.

## Descripci√≥n

**Flash Elicit** es una herramienta de elicitaci√≥n de requisitos que analiza comentarios de usuarios de aplicaciones m√≥viles (Google Play Store) para generar requisitos No Funcionales basados en las categor√≠as de seguridad de ISO 25010.

## Caracter√≠sticas Principales

- üîç **Scraping automatizado** de comentarios negativos de Google Play Store
- ü§ñ **Filtrado inteligente** con modelos BERT (binario + multiclase)
- üè∑Ô∏è **Clasificaci√≥n ISO 25010** en 6 categor√≠as de seguridad
- üß† **Generaci√≥n autom√°tica de requisitos** usando Mistral (OpenRouter)
- ‚ö° **Procesamiento individual** de comentarios con detecci√≥n de relevancia
- üìÑ **Exportaci√≥n a PDF** con formato profesional y personalizable

## Endpoints Disponibles

### 1. Scraping y Clasificaci√≥n Masiva

```
POST /api/scraping/scrape
```

Extrae comentarios de Play Store, los clasifica y genera requisitos.

**Documentaci√≥n**: Ver [README_REQUISITOS.md](README_REQUISITOS.md)

**Ejemplo**:
```bash
curl -X POST http://localhost:8000/api/scraping/scrape \
  -H "Content-Type: application/json" \
  -d '{
    "playstore_url": "https://play.google.com/store/apps/details?id=com.example.app",
    "max_reviews": 1000,
    "max_rating": 3,
    "criterios_busqueda": "recientes"
  }'
```

**Campos del Request:**
- `playstore_url` (‚úÖ requerido): URL de la app en Google Play Store
- `max_reviews` (opcional, default: 9000): N√∫mero m√°ximo de comentarios a extraer
- `max_rating` (opcional, default: 3): Calificaci√≥n m√°xima (‚â§ este valor)
- `criterios_busqueda` (‚úÖ requerido): `"recientes"` (m√°s nuevos) o `"relevantes"` (m√°s √∫tiles)

### 2. Clasificaci√≥n de Comentario Individual

```
POST /api/scraping/classify-single
```

Clasifica un solo comentario y genera un requisito si es relevante.

**Documentaci√≥n**: Ver [README_SINGLE_COMMENT.md](README_SINGLE_COMMENT.md)

**Ejemplo**:
```bash
curl -X POST http://localhost:8000/api/scraping/classify-single \
  -H "Content-Type: application/json" \
  -d '{
    "comentario": "No puedo iniciar sesi√≥n con mi huella digital",
    "calificacion": 2
  }'
```

### 3. Generaci√≥n de PDF de Requisitos

```
POST /api/scraping/generate-pdf
```

Genera un documento PDF profesional con los requisitos No Funcionales.

**Documentaci√≥n**: Ver [README_PDF.md](README_PDF.md)

**Ejemplo**:
```bash
curl -X POST http://localhost:8000/api/scraping/generate-pdf \
  -H "Content-Type: application/json" \
  -d @requisitos_data.json \
  --output requisitos.pdf
```

### 4. Health Check

```
GET /api/health
```

Verifica el estado de la API.

**Ejemplo**:
```bash
curl http://localhost:8000/api/health
```

## Instalaci√≥n y Configuraci√≥n

### Requisitos

- Python 3.8+
- GPU (opcional, para aceleraci√≥n)
- Cuenta en [OpenRouter](https://openrouter.ai/)

### 1. Clonar el repositorio

```bash
git clone <repository-url>
cd backend
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3. Configurar variables de entorno

```bash
# Copiar el archivo de ejemplo
cp .env.example .env

# Editar .env y agregar tu API key de OpenRouter
# OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxx
```

Para obtener una API key:
1. Ve a [OpenRouter](https://openrouter.ai/)
2. Crea una cuenta
3. Ve a [API Keys](https://openrouter.ai/keys)
4. Genera una nueva key

### 4. Ejecutar el servidor

```bash
python main.py
```

El servidor estar√° disponible en: http://localhost:8000

## Arquitectura

```
üì¶ backend/
‚îú‚îÄ‚îÄ üìÇ app/
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ api/routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health.py                  # Health check endpoint
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraping.py                # Endpoints principales
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraping_service.py        # Servicio de scraping
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bert_classifier_service.py # Clasificaci√≥n BERT
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openrouter_service.py      # Generaci√≥n de requisitos
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ schemas/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraping_schemas.py        # Schemas Pydantic
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ models/
‚îÇ       ‚îú‚îÄ‚îÄ modelo_bert_binario/       # Modelo filtro relevancia
‚îÇ       ‚îî‚îÄ‚îÄ modelo_bert_multiclase/    # Modelo clasificaci√≥n ISO
‚îú‚îÄ‚îÄ üìÑ main.py                         # Entry point
‚îú‚îÄ‚îÄ üìÑ requirements.txt                # Dependencias
‚îú‚îÄ‚îÄ üìÑ .env.example                    # Plantilla de configuraci√≥n
‚îî‚îÄ‚îÄ üìÑ test_*.py                       # Scripts de prueba
```

## Pipeline de Procesamiento

### Endpoint de Scraping (`/scrape`)

```
1. Scraping ‚Üí Google Play Store
   ‚Üì
2. Filtro Binario ‚Üí Relevante vs No Relevante
   ‚Üì
3. Clasificaci√≥n Multiclase ‚Üí Categor√≠as ISO 25010
   ‚Üì
4. Generaci√≥n de Requisitos ‚Üí Mistral (OpenRouter)
   ‚Üì
5. Response ‚Üí Comentarios + Requisitos
```

### Endpoint Individual (`/classify-single`)

```
1. Recibe Comentario
   ‚Üì
2. Filtro Binario ‚Üí ¬øEs relevante?
   ‚Üì
   ‚îú‚îÄ NO ‚Üí Mensaje "no relevante"
   ‚îÇ
   ‚îî‚îÄ S√ç ‚Üí Clasificaci√≥n Multiclase
      ‚Üì
      Generaci√≥n de Requisito
      ‚Üì
      Response ‚Üí Comentario + Requisito
```

## Categor√≠as ISO 25010

| Categor√≠a | Descripci√≥n | Ejemplo |
|-----------|-------------|---------|
| `autenticidad` | Verificaci√≥n de identidad | "No funciona la huella digital" |
| `confidencialidad` | Privacidad de datos | "Solicita permisos innecesarios" |
| `integridad` | Protecci√≥n contra corrupci√≥n | "Se pierden los datos guardados" |
| `no_repudio` | Trazabilidad de acciones | "No puedo ver el historial de movimientos" |
| `resistencia` | Disponibilidad del sistema | "La app se cae constantemente" |
| `responsabilidad` | Auditor√≠a y accountability | "No hay registro de qui√©n modific√≥ mis datos" |

## Modelos Utilizados

### BERT (Local)

- **Modelo base**: `dccuchile/bert-base-spanish-wwm-uncased`
- **Binario**: Clasificaci√≥n relevante/no relevante (78.5% precisi√≥n)
- **Multiclase**: Clasificaci√≥n en 6 categor√≠as ISO 25010 (74.1% F1-Score)
- **Idioma**: Espa√±ol
- **Hardware**: CPU/GPU autom√°tico

### Mistral (OpenRouter)

- **Modelo**: `mistralai/mistral-small-3.2-24b-instruct:free`
- **Proveedor**: OpenRouter
- **Costo**: Gratuito
- **Uso**: Generaci√≥n de requisitos No Funcionales

## Testing

### Scripts de Prueba

```bash
# Probar endpoint de scraping
python test_api.py

# Probar endpoint de comentario individual
python test_single_comment.py

# Probar modelos BERT directamente
python test_models.py
```

### Ejemplos de Prueba

**Comentario Relevante**:
```json
{
  "comentario": "No puedo iniciar sesi√≥n con mi huella digital",
  "calificacion": 2
}
```

**Comentario No Relevante**:
```json
{
  "comentario": "Me gusta la interfaz de la app",
  "calificacion": 5
}
```

## Documentaci√≥n de la API

FastAPI genera documentaci√≥n interactiva autom√°tica:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## Estructura de Respuesta

### Scraping Response

```json
{
  "success": true,
  "app_id": "com.example.app",
  "total_reviews": 450,
  "reviews": [...],
  "stats": {...},
  "requirements": {
    "requisitos": [
      {
        "id": "NFR-001",
        "categoria": "autenticidad",
        "requisito": "El sistema debe...",
        "prioridad": "Alta",
        "justificacion": "...",
        "criterios_aceptacion": [...]
      }
    ],
    "resumen": {...}
  }
}
```

### Single Comment Response (Relevante)

```json
{
  "success": true,
  "es_relevante": true,
  "mensaje": "Comentario clasificado como relevante...",
  "comentario": "...",
  "calificacion": 2,
  "categoria": "autenticidad",
  "confianza": 0.9523,
  "requisito": {
    "id": "NFR-001",
    "categoria": "autenticidad",
    "requisito": "El sistema debe...",
    "prioridad": "Alta",
    "justificacion": "...",
    "criterios_aceptacion": [...]
  }
}
```

### Single Comment Response (No Relevante)

```json
{
  "success": true,
  "es_relevante": false,
  "mensaje": "El comentario no fue clasificado como relevante...",
  "comentario": "...",
  "calificacion": 5,
  "categoria": null,
  "confianza": null,
  "requisito": null
}
```

## Performance

| M√©trica | Valor |
|---------|-------|
| Scraping (1000 reviews) | ~30-60 segundos |
| Clasificaci√≥n binaria | ~0.1s por comentario |
| Clasificaci√≥n multiclase | ~0.2s por comentario |
| Generaci√≥n de requisito | ~2-5 segundos |
| Endpoint individual | ~2-10 segundos total |

## Manejo de Errores

### Graceful Degradation

- Si falla el scraping ‚Üí Error 500
- Si falla la clasificaci√≥n ‚Üí Error 500
- Si falla la generaci√≥n de requisitos ‚Üí Contin√∫a sin requisitos
- Si el comentario no es relevante ‚Üí Mensaje espec√≠fico (no es error)

### Logs Detallados

El servidor muestra logs en consola con el progreso:

```
============================================================
üöÄ INICIANDO PROCESO DE SCRAPING Y CLASIFICACI√ìN
============================================================

‚úÖ Scraping completado: 1200 comentarios extra√≠dos

============================================================
ü§ñ INICIANDO CLASIFICACI√ìN CON MODELOS BERT
============================================================

‚úÖ CLASIFICACI√ìN COMPLETADA
Total scrapeado: 1200
Total relevante: 450
Tasa de relevancia: 37.5%

============================================================
üß† GENERANDO REQUISITOS NO FUNCIONALES CON MISTRAL
============================================================

‚úÖ Requisitos generados exitosamente
Total: 8 requisitos

============================================================
‚úÖ PROCESO COMPLETO FINALIZADO
============================================================
```

## Casos de Uso

### 1. An√°lisis de Competencia

Analiza aplicaciones competidoras para identificar problemas de seguridad:

```python
competitors = ["com.competitor1.app", "com.competitor2.app"]

for app_id in competitors:
    results = scrape_and_classify(app_id)
    analyze_requirements(results)
```

### 2. Monitoreo Continuo

Monitorea tu propia aplicaci√≥n peri√≥dicamente:

```python
# Ejecutar diariamente
schedule.every().day.at("00:00").do(
    lambda: scrape_and_classify("com.myapp.id")
)
```

### 3. Validaci√≥n de Feedback

Valida feedback de usuarios en tiempo real:

```javascript
async function submitFeedback(comment) {
  const result = await classifySingleComment(comment);
  if (result.es_relevante) {
    alertSecurityTeam(result.requisito);
  }
}
```

## Limitaciones

- Solo soporta Google Play Store (no App Store)
- Scraping limitado por rate limits de Google
- Modelos BERT entrenados solo en espa√±ol
- Clasificaci√≥n limitada a 6 categor√≠as de seguridad ISO 25010
- Generaci√≥n de requisitos depende de disponibilidad de OpenRouter

## Mejoras Futuras

- [ ] Soporte para App Store (iOS)
- [ ] Modelos multiling√ºes (ingl√©s, portugu√©s, etc.)
- [ ] M√°s categor√≠as ISO 25010 (usabilidad, performance, etc.)
- [ ] Batch processing para m√∫ltiples comentarios
- [ ] Cache de requisitos generados
- [ ] Exportaci√≥n a PDF/DOCX
- [ ] Integraci√≥n con Jira/Azure DevOps
- [ ] Dashboard web para visualizaci√≥n
- [ ] API de refinamiento de requisitos

## Documentaci√≥n Adicional

- [README_CLASIFICACION.md](README_CLASIFICACION.md) - Detalles de modelos BERT
- [README_REQUISITOS.md](README_REQUISITOS.md) - Endpoint de scraping masivo
- [README_SINGLE_COMMENT.md](README_SINGLE_COMMENT.md) - Endpoint de comentario individual
- [README_PDF.md](README_PDF.md) - Generaci√≥n de PDF de requisitos

## Licencia

[Tu licencia aqu√≠]

## Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork el repositorio
2. Crea una rama para tu feature
3. Haz commit de tus cambios
4. Abre un Pull Request

## Soporte

Para reportar problemas o sugerencias:
- Abre un issue en el repositorio
- Contacta al equipo de desarrollo

## Cr√©ditos

- Modelos BERT: [dccuchile/bert-base-spanish-wwm-uncased](https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased)
- LLM: [Mistral AI](https://mistral.ai/) via [OpenRouter](https://openrouter.ai/)
- Framework: [FastAPI](https://fastapi.tiangolo.com/)
- Scraping: [google-play-scraper](https://github.com/JoMingyu/google-play-scraper)
